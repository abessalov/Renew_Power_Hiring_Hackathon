{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Xgboost best parameters searching\n",
    "- train separately for each turbine_id\n",
    "- max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "plt.style.use('seaborn')\n",
    "pd.options.display.float_format = '{:,.5f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = dt.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train dataset\n",
    "df1 = pd.read_csv('data/train.csv')\n",
    "df1['row_id'] = range(len(df1))\n",
    "\n",
    "# read test dataset\n",
    "df2 = pd.read_csv('data/new/test.csv')\n",
    "df2['row_id'] = range(len(df2))\n",
    "df2['row_id'] = df2['row_id']  + 1000000\n",
    "\n",
    "# merge\n",
    "df = pd.concat([df1,df2])\n",
    "del df1,df2\n",
    "gc.collect()\n",
    "\n",
    "# add fold for splitting\n",
    "np.random.seed(1234)\n",
    "df['fold'] = np.random.randint(0,3,len(df))\n",
    "# drop some features\n",
    "feats_drop = ['timestamp','active_power_calculated_by_converter','reactice_power_calculated_by_converter']\n",
    "for f in feats_drop:\n",
    "    if f in df.columns:\n",
    "        del df[f]\n",
    "# label encoder of categorical feats\n",
    "feats_cat = ['turbine_id']\n",
    "list_lbl  = []\n",
    "for f in feats_cat:\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    df[f] = lbl.fit_transform(df[f])\n",
    "    list_lbl.append(lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_used = [   \n",
    "    \"active_power_raw\",\n",
    "    \"ambient_temperature\",\n",
    "    \"generator_speed\",\n",
    "    \"generator_winding_temp_max\",\n",
    "    \"grid_power10min_average\",\n",
    "    \"nc1_inside_temp\",\n",
    "    \"nacelle_temp\",\n",
    "    \"reactive_power\",\n",
    "    \"wind_direction_raw\",\n",
    "    \"wind_speed_raw\",\n",
    "    \"wind_speed_turbulence\",  \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ts_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        'mae': metrics.mean_absolute_error(y_true, y_pred),\n",
    "        'mse': metrics.mean_squared_error(y_true, y_pred),\n",
    "        'mape': np.mean(np.abs((y_true - y_pred) / y_true)),\n",
    "        'smape': np.mean(np.abs( 2*(y_true - y_pred) / (y_true+np.abs(y_pred)))),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_sets():\n",
    "    # Sets creation\n",
    "    feat_target = 'Target'\n",
    "\n",
    "    filt_fold  = df.fold == 0\n",
    "    filt_null  = df[feat_target].isnull()\n",
    "    filt_turb  = df.turbine_id == turb\n",
    "\n",
    "    filt_train = ~filt_fold & ~filt_null & filt_turb\n",
    "    filt_valid = filt_fold & ~filt_null & filt_turb\n",
    "    filt_test  = filt_null & filt_turb\n",
    "\n",
    "    x, y   = df[filt_train][feats_used], df[filt_train][feat_target]\n",
    "    xv, yv = df[filt_valid][feats_used], df[filt_valid][feat_target]\n",
    "    xt, yt = df[filt_test][feats_used],  df[filt_test][feat_target]\n",
    "    # print(x.shape, xv.shape, xt.shape)\n",
    "    \n",
    "    x_ = xgb.DMatrix(x.values, \n",
    "                label = y, \n",
    "                feature_names = feats_used)\n",
    "    xv_ = xgb.DMatrix(xv.values, \n",
    "                label = yv, \n",
    "                feature_names = feats_used)\n",
    "    return x,y,x_,xv,yv,xv_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xgb_search():\n",
    "    params = {\n",
    "        'booster': 'gbtree',\n",
    "        'tree_method': 'hist',\n",
    "        'objective': 'reg:squarederror', \n",
    "        # 'eval_metric': 'logloss',\n",
    "        'eta': 0.1,\n",
    "        'max_depth': 6,  # -1 means no limit\n",
    "        'subsample': 1,  # Subsample ratio of the training instance.\n",
    "        'colsample_bytree': 1,  # Subsample ratio of columns when constructing each tree.\n",
    "        'reg_alpha': 0,  # L1 regularization term on weights\n",
    "        'reg_lambda': 0,  # L2 regularization term on weights\n",
    "        'nthread': -1,\n",
    "        'verbosity': 0\n",
    "    } \n",
    "    list1 = list()\n",
    "    list2 = list()\n",
    "    list3 = list()\n",
    "    list4 = list()\n",
    "    for max_depth in [5,6,7,8,9,10]:\n",
    "        for subsample in [1]:\n",
    "            for colsample_bytree in [1]:\n",
    "                # fitting\n",
    "                params['max_depth'] = max_depth\n",
    "                params['subsample'] = subsample\n",
    "                params['colsample_bytree'] = colsample_bytree\n",
    "                evals_results = {}\n",
    "                model_xgb     = xgb.train(params,\n",
    "                                        x_,\n",
    "                                         evals=[\n",
    "                                             (x_,'train'), \n",
    "                                             (xv_,'valid'),\n",
    "                                         ],  \n",
    "                                        evals_result=evals_results,\n",
    "                                        num_boost_round=10000,\n",
    "                                        early_stopping_rounds=50,\n",
    "                                        verbose_eval=50000, \n",
    "                                        feval=None) \n",
    "                pred = model_xgb.predict(xv_)\n",
    "                res = ts_metrics(yv, pred)\n",
    "                list1.append(res)\n",
    "                list2.append(max_depth)\n",
    "                list3.append(subsample)\n",
    "                list4.append(colsample_bytree)\n",
    "                \n",
    "    df_out = pd.DataFrame(list1)\n",
    "    df_out['max_depth'] = list2\n",
    "    df_out['subsample'] = list3\n",
    "    df_out['colsample_bytree'] = list4\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "turb = 0\n",
      "0:00:00.001000\n",
      "[0]\ttrain-rmse:44.02285\tvalid-rmse:44.02081\n",
      "[2018]\ttrain-rmse:0.66254\tvalid-rmse:1.40305\n",
      "[0]\ttrain-rmse:44.02179\tvalid-rmse:44.02030\n",
      "[1362]\ttrain-rmse:0.53467\tvalid-rmse:1.38593\n",
      "[0]\ttrain-rmse:44.02081\tvalid-rmse:44.01949\n",
      "[1033]\ttrain-rmse:0.39374\tvalid-rmse:1.37285\n",
      "[0]\ttrain-rmse:44.01970\tvalid-rmse:44.01837\n",
      "[744]\ttrain-rmse:0.31343\tvalid-rmse:1.37153\n",
      "[0]\ttrain-rmse:44.01889\tvalid-rmse:44.01692\n",
      "[975]\ttrain-rmse:0.08956\tvalid-rmse:1.35853\n",
      "[0]\ttrain-rmse:44.01802\tvalid-rmse:44.01544\n",
      "[1404]\ttrain-rmse:0.00894\tvalid-rmse:1.35585\n",
      "------------\n",
      "turb = 1\n",
      "0:01:12.149195\n",
      "[0]\ttrain-rmse:42.07700\tvalid-rmse:42.05416\n",
      "[1104]\ttrain-rmse:0.63386\tvalid-rmse:1.01880\n",
      "[0]\ttrain-rmse:42.07668\tvalid-rmse:42.05430\n",
      "[1228]\ttrain-rmse:0.42514\tvalid-rmse:0.99243\n",
      "[0]\ttrain-rmse:42.07645\tvalid-rmse:42.05403\n",
      "[832]\ttrain-rmse:0.36406\tvalid-rmse:0.97959\n",
      "[0]\ttrain-rmse:42.07620\tvalid-rmse:42.05423\n",
      "[1257]\ttrain-rmse:0.11825\tvalid-rmse:0.95686\n",
      "[0]\ttrain-rmse:42.07595\tvalid-rmse:42.05412\n",
      "[1049]\ttrain-rmse:0.06353\tvalid-rmse:0.95005\n",
      "[0]\ttrain-rmse:42.07568\tvalid-rmse:42.05384\n",
      "[1783]\ttrain-rmse:0.00336\tvalid-rmse:0.94989\n",
      "------------\n",
      "turb = 2\n",
      "0:02:35.359244\n",
      "[0]\ttrain-rmse:40.62587\tvalid-rmse:40.63667\n",
      "[2390]\ttrain-rmse:0.33743\tvalid-rmse:0.70665\n",
      "[0]\ttrain-rmse:40.62568\tvalid-rmse:40.63654\n",
      "[1741]\ttrain-rmse:0.24541\tvalid-rmse:0.69827\n",
      "[0]\ttrain-rmse:40.62553\tvalid-rmse:40.63645\n",
      "[1968]\ttrain-rmse:0.09579\tvalid-rmse:0.68200\n",
      "[0]\ttrain-rmse:40.62538\tvalid-rmse:40.63618\n",
      "[2104]\ttrain-rmse:0.02564\tvalid-rmse:0.67565\n",
      "[0]\ttrain-rmse:40.62519\tvalid-rmse:40.63598\n",
      "[2072]\ttrain-rmse:0.00519\tvalid-rmse:0.67404\n",
      "[0]\ttrain-rmse:40.62501\tvalid-rmse:40.63593\n",
      "[1126]\ttrain-rmse:0.01102\tvalid-rmse:0.67114\n",
      "------------\n",
      "turb = 3\n",
      "0:04:30.991345\n",
      "[0]\ttrain-rmse:41.52604\tvalid-rmse:41.53390\n",
      "[3906]\ttrain-rmse:0.26057\tvalid-rmse:0.81887\n",
      "[0]\ttrain-rmse:41.52558\tvalid-rmse:41.53335\n",
      "[3060]\ttrain-rmse:0.14268\tvalid-rmse:0.79592\n",
      "[0]\ttrain-rmse:41.52521\tvalid-rmse:41.53312\n",
      "[4533]\ttrain-rmse:0.01505\tvalid-rmse:0.77868\n",
      "[0]\ttrain-rmse:41.52488\tvalid-rmse:41.53263\n",
      "[3704]\ttrain-rmse:0.00406\tvalid-rmse:0.75769\n",
      "[0]\ttrain-rmse:41.52453\tvalid-rmse:41.53184\n",
      "[2396]\ttrain-rmse:0.00337\tvalid-rmse:0.74871\n",
      "[0]\ttrain-rmse:41.52422\tvalid-rmse:41.53124\n",
      "[1680]\ttrain-rmse:0.00298\tvalid-rmse:0.73825\n",
      "------------\n",
      "turb = 4\n",
      "0:07:23.749471\n",
      "[0]\ttrain-rmse:41.47722\tvalid-rmse:41.48594\n",
      "[1269]\ttrain-rmse:0.57900\tvalid-rmse:0.92263\n",
      "[0]\ttrain-rmse:41.47700\tvalid-rmse:41.48610\n",
      "[809]\ttrain-rmse:0.52611\tvalid-rmse:0.91001\n",
      "[0]\ttrain-rmse:41.47679\tvalid-rmse:41.48576\n",
      "[1144]\ttrain-rmse:0.28141\tvalid-rmse:0.89673\n",
      "[0]\ttrain-rmse:41.47659\tvalid-rmse:41.48539\n",
      "[608]\ttrain-rmse:0.30790\tvalid-rmse:0.88697\n",
      "[0]\ttrain-rmse:41.47638\tvalid-rmse:41.48537\n",
      "[739]\ttrain-rmse:0.14164\tvalid-rmse:0.88240\n",
      "[0]\ttrain-rmse:41.47618\tvalid-rmse:41.48543\n",
      "[414]\ttrain-rmse:0.16424\tvalid-rmse:0.87842\n",
      "------------\n",
      "turb = 5\n",
      "0:08:10.035338\n",
      "[0]\ttrain-rmse:40.55488\tvalid-rmse:40.59409\n",
      "[1965]\ttrain-rmse:0.53799\tvalid-rmse:0.97742\n",
      "[0]\ttrain-rmse:40.55465\tvalid-rmse:40.59380\n",
      "[1161]\ttrain-rmse:0.48233\tvalid-rmse:0.96609\n",
      "[0]\ttrain-rmse:40.55438\tvalid-rmse:40.59356\n",
      "[974]\ttrain-rmse:0.35134\tvalid-rmse:0.95170\n",
      "[0]\ttrain-rmse:40.55411\tvalid-rmse:40.59369\n",
      "[710]\ttrain-rmse:0.27859\tvalid-rmse:0.94049\n",
      "[0]\ttrain-rmse:40.55385\tvalid-rmse:40.59295\n",
      "[645]\ttrain-rmse:0.17525\tvalid-rmse:0.93220\n",
      "[0]\ttrain-rmse:40.55354\tvalid-rmse:40.59299\n",
      "[510]\ttrain-rmse:0.12547\tvalid-rmse:0.92613\n",
      "------------\n",
      "turb = 6\n",
      "0:09:02.665044\n",
      "[0]\ttrain-rmse:39.76266\tvalid-rmse:39.76179\n",
      "[1031]\ttrain-rmse:0.51949\tvalid-rmse:0.74229\n",
      "[0]\ttrain-rmse:39.76253\tvalid-rmse:39.76152\n",
      "[950]\ttrain-rmse:0.40582\tvalid-rmse:0.73040\n",
      "[0]\ttrain-rmse:39.76240\tvalid-rmse:39.76166\n",
      "[803]\ttrain-rmse:0.31343\tvalid-rmse:0.72724\n",
      "[0]\ttrain-rmse:39.76228\tvalid-rmse:39.76123\n",
      "[484]\ttrain-rmse:0.30717\tvalid-rmse:0.71835\n",
      "[0]\ttrain-rmse:39.76214\tvalid-rmse:39.76095\n",
      "[410]\ttrain-rmse:0.23484\tvalid-rmse:0.71264\n",
      "[0]\ttrain-rmse:39.76199\tvalid-rmse:39.76088\n",
      "[543]\ttrain-rmse:0.09299\tvalid-rmse:0.70574\n",
      "------------\n",
      "turb = 7\n",
      "0:09:44.973457\n",
      "[0]\ttrain-rmse:41.76882\tvalid-rmse:41.75163\n",
      "[3152]\ttrain-rmse:0.32478\tvalid-rmse:0.81548\n",
      "[0]\ttrain-rmse:41.76861\tvalid-rmse:41.75154\n",
      "[1925]\ttrain-rmse:0.25859\tvalid-rmse:0.80734\n",
      "[0]\ttrain-rmse:41.76830\tvalid-rmse:41.75088\n",
      "[2258]\ttrain-rmse:0.08618\tvalid-rmse:0.78944\n",
      "[0]\ttrain-rmse:41.76806\tvalid-rmse:41.75081\n",
      "[1724]\ttrain-rmse:0.05091\tvalid-rmse:0.78652\n",
      "[0]\ttrain-rmse:41.76784\tvalid-rmse:41.75035\n",
      "[1358]\ttrain-rmse:0.02529\tvalid-rmse:0.77997\n",
      "[0]\ttrain-rmse:41.76762\tvalid-rmse:41.74992\n",
      "[1639]\ttrain-rmse:0.00295\tvalid-rmse:0.76399\n",
      "------------\n",
      "turb = 8\n",
      "0:11:58.222886\n",
      "[0]\ttrain-rmse:40.67786\tvalid-rmse:40.66136\n",
      "[2007]\ttrain-rmse:0.41279\tvalid-rmse:0.81375\n",
      "[0]\ttrain-rmse:40.67760\tvalid-rmse:40.66077\n",
      "[1154]\ttrain-rmse:0.37514\tvalid-rmse:0.80718\n",
      "[0]\ttrain-rmse:40.67735\tvalid-rmse:40.66080\n",
      "[1243]\ttrain-rmse:0.20636\tvalid-rmse:0.79512\n",
      "[0]\ttrain-rmse:40.67716\tvalid-rmse:40.66050\n",
      "[1538]\ttrain-rmse:0.06145\tvalid-rmse:0.77989\n",
      "[0]\ttrain-rmse:40.67697\tvalid-rmse:40.66033\n",
      "[1193]\ttrain-rmse:0.03747\tvalid-rmse:0.78176\n",
      "[0]\ttrain-rmse:40.67678\tvalid-rmse:40.66005\n",
      "[1461]\ttrain-rmse:0.00462\tvalid-rmse:0.77368\n",
      "------------\n",
      "turb = 9\n",
      "0:13:37.437673\n",
      "[0]\ttrain-rmse:42.54259\tvalid-rmse:42.52512\n",
      "[3302]\ttrain-rmse:0.29521\tvalid-rmse:0.74610\n",
      "[0]\ttrain-rmse:42.54239\tvalid-rmse:42.52503\n",
      "[2759]\ttrain-rmse:0.17058\tvalid-rmse:0.72505\n",
      "[0]\ttrain-rmse:42.54223\tvalid-rmse:42.52501\n",
      "[2235]\ttrain-rmse:0.09433\tvalid-rmse:0.70081\n",
      "[0]\ttrain-rmse:42.54207\tvalid-rmse:42.52506\n",
      "[2530]\ttrain-rmse:0.01901\tvalid-rmse:0.69272\n",
      "[0]\ttrain-rmse:42.54184\tvalid-rmse:42.52525\n",
      "[2488]\ttrain-rmse:0.00386\tvalid-rmse:0.69053\n",
      "[0]\ttrain-rmse:42.54168\tvalid-rmse:42.52480\n",
      "[1734]\ttrain-rmse:0.00352\tvalid-rmse:0.68576\n",
      "------------\n",
      "turb = 10\n",
      "0:16:17.710075\n",
      "[0]\ttrain-rmse:41.33851\tvalid-rmse:41.31511\n",
      "[1663]\ttrain-rmse:0.50359\tvalid-rmse:0.84778\n",
      "[0]\ttrain-rmse:41.33832\tvalid-rmse:41.31530\n",
      "[1866]\ttrain-rmse:0.28815\tvalid-rmse:0.83381\n",
      "[0]\ttrain-rmse:41.33817\tvalid-rmse:41.31514\n",
      "[550]\ttrain-rmse:0.45187\tvalid-rmse:0.83615\n",
      "[0]\ttrain-rmse:41.33803\tvalid-rmse:41.31527\n",
      "[566]\ttrain-rmse:0.30081\tvalid-rmse:0.81907\n",
      "[0]\ttrain-rmse:41.33785\tvalid-rmse:41.31585\n",
      "[530]\ttrain-rmse:0.19169\tvalid-rmse:0.81304\n",
      "[0]\ttrain-rmse:41.33765\tvalid-rmse:41.31587\n",
      "[1020]\ttrain-rmse:0.01934\tvalid-rmse:0.80210\n",
      "------------\n",
      "turb = 11\n",
      "0:17:27.292530\n",
      "[0]\ttrain-rmse:40.60211\tvalid-rmse:40.60239\n",
      "[1833]\ttrain-rmse:0.52435\tvalid-rmse:0.99219\n",
      "[0]\ttrain-rmse:40.60175\tvalid-rmse:40.60172\n",
      "[1092]\ttrain-rmse:0.46996\tvalid-rmse:0.98377\n",
      "[0]\ttrain-rmse:40.60135\tvalid-rmse:40.60151\n",
      "[809]\ttrain-rmse:0.37587\tvalid-rmse:0.96455\n",
      "[0]\ttrain-rmse:40.60107\tvalid-rmse:40.60136\n",
      "[809]\ttrain-rmse:0.23571\tvalid-rmse:0.95532\n",
      "[0]\ttrain-rmse:40.60081\tvalid-rmse:40.60124\n",
      "[595]\ttrain-rmse:0.18557\tvalid-rmse:0.95049\n",
      "[0]\ttrain-rmse:40.60046\tvalid-rmse:40.60081\n",
      "[410]\ttrain-rmse:0.17274\tvalid-rmse:0.94434\n",
      "------------\n",
      "turb = 12\n",
      "0:18:24.925478\n",
      "[0]\ttrain-rmse:40.25869\tvalid-rmse:40.24825\n",
      "[1933]\ttrain-rmse:0.44709\tvalid-rmse:0.79069\n",
      "[0]\ttrain-rmse:40.25853\tvalid-rmse:40.24773\n",
      "[1007]\ttrain-rmse:0.42849\tvalid-rmse:0.78254\n",
      "[0]\ttrain-rmse:40.25834\tvalid-rmse:40.24774\n",
      "[1105]\ttrain-rmse:0.25594\tvalid-rmse:0.76718\n",
      "[0]\ttrain-rmse:40.25815\tvalid-rmse:40.24740\n",
      "[983]\ttrain-rmse:0.15025\tvalid-rmse:0.75965\n",
      "[0]\ttrain-rmse:40.25796\tvalid-rmse:40.24707\n",
      "[1879]\ttrain-rmse:0.00952\tvalid-rmse:0.75428\n",
      "[0]\ttrain-rmse:40.25777\tvalid-rmse:40.24687\n",
      "[670]\ttrain-rmse:0.06288\tvalid-rmse:0.74850\n",
      "------------\n",
      "turb = 13\n",
      "0:19:53.756695\n",
      "[0]\ttrain-rmse:39.59514\tvalid-rmse:39.61805\n",
      "[2228]\ttrain-rmse:0.30159\tvalid-rmse:0.62522\n",
      "[0]\ttrain-rmse:39.59497\tvalid-rmse:39.61811\n",
      "[1918]\ttrain-rmse:0.19887\tvalid-rmse:0.61281\n",
      "[0]\ttrain-rmse:39.59485\tvalid-rmse:39.61803\n",
      "[1840]\ttrain-rmse:0.10022\tvalid-rmse:0.60181\n",
      "[0]\ttrain-rmse:39.59471\tvalid-rmse:39.61802\n",
      "[1535]\ttrain-rmse:0.05413\tvalid-rmse:0.58652\n",
      "[0]\ttrain-rmse:39.59456\tvalid-rmse:39.61770\n",
      "[1112]\ttrain-rmse:0.03896\tvalid-rmse:0.57914\n",
      "[0]\ttrain-rmse:39.59439\tvalid-rmse:39.61741\n",
      "[910]\ttrain-rmse:0.02389\tvalid-rmse:0.56518\n",
      "------------\n",
      "turb = 14\n",
      "0:21:30.194713\n",
      "[0]\ttrain-rmse:43.34947\tvalid-rmse:43.29021\n",
      "[2148]\ttrain-rmse:0.99368\tvalid-rmse:2.00068\n",
      "[0]\ttrain-rmse:43.34810\tvalid-rmse:43.28876\n",
      "[1562]\ttrain-rmse:0.75518\tvalid-rmse:2.01309\n",
      "[0]\ttrain-rmse:43.34641\tvalid-rmse:43.28793\n",
      "[1617]\ttrain-rmse:0.37328\tvalid-rmse:2.03392\n",
      "[0]\ttrain-rmse:43.34425\tvalid-rmse:43.28593\n",
      "[1692]\ttrain-rmse:0.13270\tvalid-rmse:2.04991\n",
      "[0]\ttrain-rmse:43.34201\tvalid-rmse:43.28595\n",
      "[1427]\ttrain-rmse:0.06414\tvalid-rmse:2.07865\n",
      "[0]\ttrain-rmse:43.33966\tvalid-rmse:43.28539\n",
      "[1046]\ttrain-rmse:0.04834\tvalid-rmse:2.15074\n",
      "------------\n",
      "turb = 15\n",
      "0:23:12.187723\n",
      "[0]\ttrain-rmse:40.84018\tvalid-rmse:40.84430\n",
      "[1964]\ttrain-rmse:0.51591\tvalid-rmse:0.93464\n",
      "[0]\ttrain-rmse:40.83992\tvalid-rmse:40.84418\n",
      "[1705]\ttrain-rmse:0.35611\tvalid-rmse:0.91965\n",
      "[0]\ttrain-rmse:40.83969\tvalid-rmse:40.84391\n",
      "[1202]\ttrain-rmse:0.28412\tvalid-rmse:0.91073\n",
      "[0]\ttrain-rmse:40.83945\tvalid-rmse:40.84336\n",
      "[1331]\ttrain-rmse:0.12054\tvalid-rmse:0.90267\n",
      "[0]\ttrain-rmse:40.83921\tvalid-rmse:40.84272\n",
      "[1299]\ttrain-rmse:0.04520\tvalid-rmse:0.88876\n",
      "[0]\ttrain-rmse:40.83894\tvalid-rmse:40.84246\n",
      "[1698]\ttrain-rmse:0.00453\tvalid-rmse:0.88659\n"
     ]
    }
   ],
   "source": [
    "dt_start = dt.now()\n",
    "df_res3 = pd.DataFrame()\n",
    "for turb in range(16):\n",
    "    print('------------')\n",
    "    print('turb =', turb)\n",
    "    print(dt.now() - dt_start)\n",
    "    \n",
    "    x,y,x_,xv,yv,xv_ = prepare_sets()\n",
    "    df_res0 = xgb_search()\n",
    "    df_res0['turb'] = turb\n",
    "    df_res3 = pd.concat([df_res3, df_res0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res3.reset_index(inplace = True, drop = True)\n",
    "df_res3.to_pickle('data/df_xgb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>mape</th>\n",
       "      <th>smape</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>turb</th>\n",
       "      <th>mape_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.88855</td>\n",
       "      <td>1.83833</td>\n",
       "      <td>0.01774</td>\n",
       "      <td>0.01774</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.62698</td>\n",
       "      <td>0.90229</td>\n",
       "      <td>0.01345</td>\n",
       "      <td>0.01338</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.46768</td>\n",
       "      <td>0.45043</td>\n",
       "      <td>0.01025</td>\n",
       "      <td>0.01023</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.46803</td>\n",
       "      <td>0.54502</td>\n",
       "      <td>0.01019</td>\n",
       "      <td>0.01014</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.60402</td>\n",
       "      <td>0.77163</td>\n",
       "      <td>0.01302</td>\n",
       "      <td>0.01298</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.67460</td>\n",
       "      <td>0.85772</td>\n",
       "      <td>0.01479</td>\n",
       "      <td>0.01477</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.50903</td>\n",
       "      <td>0.49806</td>\n",
       "      <td>0.01136</td>\n",
       "      <td>0.01135</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.52972</td>\n",
       "      <td>0.58368</td>\n",
       "      <td>0.01137</td>\n",
       "      <td>0.01134</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.01137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.53146</td>\n",
       "      <td>0.59858</td>\n",
       "      <td>0.01170</td>\n",
       "      <td>0.01167</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.48380</td>\n",
       "      <td>0.47027</td>\n",
       "      <td>0.01019</td>\n",
       "      <td>0.01017</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.01019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.58805</td>\n",
       "      <td>0.64336</td>\n",
       "      <td>0.01273</td>\n",
       "      <td>0.01271</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.65303</td>\n",
       "      <td>0.89164</td>\n",
       "      <td>0.01442</td>\n",
       "      <td>0.01436</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.01442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.54417</td>\n",
       "      <td>0.56025</td>\n",
       "      <td>0.01202</td>\n",
       "      <td>0.01200</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.01202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.39002</td>\n",
       "      <td>0.31942</td>\n",
       "      <td>0.00880</td>\n",
       "      <td>0.00878</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.00880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1.38538</td>\n",
       "      <td>4.05254</td>\n",
       "      <td>0.02786</td>\n",
       "      <td>0.02787</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.02786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.62220</td>\n",
       "      <td>0.78604</td>\n",
       "      <td>0.01365</td>\n",
       "      <td>0.01360</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.01365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mae     mse    mape   smape  max_depth  subsample  colsample_bytree  \\\n",
       "5  0.88855 1.83833 0.01774 0.01774         10          1                 1   \n",
       "11 0.62698 0.90229 0.01345 0.01338         10          1                 1   \n",
       "17 0.46768 0.45043 0.01025 0.01023         10          1                 1   \n",
       "23 0.46803 0.54502 0.01019 0.01014         10          1                 1   \n",
       "29 0.60402 0.77163 0.01302 0.01298         10          1                 1   \n",
       "35 0.67460 0.85772 0.01479 0.01477         10          1                 1   \n",
       "41 0.50903 0.49806 0.01136 0.01135         10          1                 1   \n",
       "47 0.52972 0.58368 0.01137 0.01134         10          1                 1   \n",
       "53 0.53146 0.59858 0.01170 0.01167         10          1                 1   \n",
       "59 0.48380 0.47027 0.01019 0.01017         10          1                 1   \n",
       "65 0.58805 0.64336 0.01273 0.01271         10          1                 1   \n",
       "71 0.65303 0.89164 0.01442 0.01436         10          1                 1   \n",
       "77 0.54417 0.56025 0.01202 0.01200         10          1                 1   \n",
       "83 0.39002 0.31942 0.00880 0.00878         10          1                 1   \n",
       "85 1.38538 4.05254 0.02786 0.02787          6          1                 1   \n",
       "95 0.62220 0.78604 0.01365 0.01360         10          1                 1   \n",
       "\n",
       "    turb  mape_min  \n",
       "5      0   0.01774  \n",
       "11     1   0.01345  \n",
       "17     2   0.01025  \n",
       "23     3   0.01019  \n",
       "29     4   0.01302  \n",
       "35     5   0.01479  \n",
       "41     6   0.01136  \n",
       "47     7   0.01137  \n",
       "53     8   0.01170  \n",
       "59     9   0.01019  \n",
       "65    10   0.01273  \n",
       "71    11   0.01442  \n",
       "77    12   0.01202  \n",
       "83    13   0.00880  \n",
       "85    14   0.02786  \n",
       "95    15   0.01365  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res3 = pd.read_pickle('data/df_xgb.pkl')\n",
    "df_res3['mape_min'] = df_res3.groupby('turb').mape.transform(min)\n",
    "f1 = df_res3.mape_min == df_res3.mape\n",
    "df_res4 = df_res3[f1]\n",
    "df_res4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013346417779854871"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res4.mape.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working time:  0:26:02.917938\n"
     ]
    }
   ],
   "source": [
    "print('Working time: ', dt.now() - time_start) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
